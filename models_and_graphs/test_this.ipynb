{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pingouin as pg \n",
    "import lightgbm as lgb \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fixed_projects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_values = {'Illicit':1, 'likely-reputable':0}\n",
    "# replace_values = {1:'Illicit', 0:'likely-reputable'}\n",
    "df['FLAG'] = df['FLAG'].replace(replace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Address', 'FLAG'], axis=1)\n",
    "y = df['FLAG']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferential Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1376/4228884520.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n"
     ]
    }
   ],
   "source": [
    "# Correlation between inputs \n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "X.drop(columns=to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lgbm_classifier(X_train, y_train, X_test, y_test):\n",
    "#     clf = lgb.LGBMClassifier(learning_rate=0.09,\n",
    "#                              max_depth=4,\n",
    "#                              subsample=0.5, \n",
    "#                              objective='binary',\n",
    "#                              n_estimators=300)\n",
    "#     eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "#     # clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=[\"error\", \"logloss\"],\n",
    "#     #           eval_set=eval_set, verbose=True)\n",
    "#     clf.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)],\n",
    "#           verbose=20, eval_metric='logloss')\n",
    "    \n",
    "#     # predict\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     predicted_values = [round(val) for val in y_pred]\n",
    "\n",
    "#     # evaluation \n",
    "#     accuracy = accuracy_score(y_test, predicted_values)\n",
    "#     print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "#     # performance metrics \n",
    "#     results = clf.evals_result_\n",
    "#     epochs = len(results['validation_0']['error'])\n",
    "#     x_axis = range(0, epochs)\n",
    "#     plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "#     # plotting log loss\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "#     ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "#     ax.legend()\n",
    "#     plt.ylabel('Log Loss')\n",
    "#     plt.xlabel('Number of iterations')\n",
    "#     plt.title('LightGBM Log Loss')\n",
    "#     plt.show()\n",
    "#     # plot classification error\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "#     ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "#     ax.legend()\n",
    "#     plt.ylabel('Classification Error')\n",
    "#     plt.xlabel('Number of iterations')\n",
    "#     plt.title('LightGBM Classification Error')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold_LGBM(X, Y, n_folds):\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    print(\"Starting stratified Cross-validation using LGBM\")\n",
    "    #model1 = xgb.XGBClassifier(learning_rate=0.1, n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0,\n",
    "    #                           subsample=0.8, colsample_bytree=0.8, objective='binary:logistic',\n",
    "    #                           scale_pos_weight=1, seed=27)\n",
    "    clf = lgb.LGBMClassifier(learning_rate=0.2)\n",
    "    max_depth = [2, 3, 4, 5, 6, 7, 8]\n",
    "    n_estimators = [100, 150, 200, 250, 300]\n",
    "    param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=7)\n",
    "    score = {'f1', 'roc_auc', 'accuracy'}\n",
    "    current = time.time()\n",
    "    #results = cross_validate(model1, X, Y, cv=kfold, scoring=scoring, return_train_score=True, n_jobs=-1)\n",
    "    results = GridSearchCV(clf,param_grid, cv=kfold, scoring='roc_auc', n_jobs=6)\n",
    "    grid_result = results.fit(X, Y)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    print(\"Execution time: \", time.time() - current)\n",
    "\n",
    "    # plot results\n",
    "    scores = np.array(means).reshape(len(max_depth), len(n_estimators))\n",
    "    for i, value in enumerate(max_depth):\n",
    "        plt.plot(n_estimators, scores[i], label='depth: ' + str(value))\n",
    "    plt.legend()\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting stratified Cross-validation using LGBM\n",
      "Best: 0.999999 using {'max_depth': 2, 'n_estimators': 100}\n",
      "0.999999 (0.000003) with: {'max_depth': 2, 'n_estimators': 100}\n",
      "0.999999 (0.000003) with: {'max_depth': 2, 'n_estimators': 150}\n",
      "0.999998 (0.000007) with: {'max_depth': 2, 'n_estimators': 200}\n",
      "0.999998 (0.000007) with: {'max_depth': 2, 'n_estimators': 250}\n",
      "0.999998 (0.000007) with: {'max_depth': 2, 'n_estimators': 300}\n",
      "0.999995 (0.000014) with: {'max_depth': 3, 'n_estimators': 100}\n",
      "0.999995 (0.000014) with: {'max_depth': 3, 'n_estimators': 150}\n",
      "0.999997 (0.000010) with: {'max_depth': 3, 'n_estimators': 200}\n",
      "0.999997 (0.000010) with: {'max_depth': 3, 'n_estimators': 250}\n",
      "0.999997 (0.000010) with: {'max_depth': 3, 'n_estimators': 300}\n",
      "0.999997 (0.000010) with: {'max_depth': 4, 'n_estimators': 100}\n",
      "0.999997 (0.000010) with: {'max_depth': 4, 'n_estimators': 150}\n",
      "0.999995 (0.000014) with: {'max_depth': 4, 'n_estimators': 200}\n",
      "0.999997 (0.000010) with: {'max_depth': 4, 'n_estimators': 250}\n",
      "0.999998 (0.000007) with: {'max_depth': 4, 'n_estimators': 300}\n",
      "0.999997 (0.000005) with: {'max_depth': 5, 'n_estimators': 100}\n",
      "0.999998 (0.000005) with: {'max_depth': 5, 'n_estimators': 150}\n",
      "0.999999 (0.000003) with: {'max_depth': 5, 'n_estimators': 200}\n",
      "0.999999 (0.000003) with: {'max_depth': 5, 'n_estimators': 250}\n",
      "0.999999 (0.000003) with: {'max_depth': 5, 'n_estimators': 300}\n",
      "0.999995 (0.000008) with: {'max_depth': 6, 'n_estimators': 100}\n",
      "0.999995 (0.000008) with: {'max_depth': 6, 'n_estimators': 150}\n",
      "0.999995 (0.000008) with: {'max_depth': 6, 'n_estimators': 200}\n",
      "0.999995 (0.000008) with: {'max_depth': 6, 'n_estimators': 250}\n",
      "0.999995 (0.000008) with: {'max_depth': 6, 'n_estimators': 300}\n",
      "0.999994 (0.000011) with: {'max_depth': 7, 'n_estimators': 100}\n",
      "0.999997 (0.000007) with: {'max_depth': 7, 'n_estimators': 150}\n",
      "0.999997 (0.000007) with: {'max_depth': 7, 'n_estimators': 200}\n",
      "0.999997 (0.000007) with: {'max_depth': 7, 'n_estimators': 250}\n",
      "0.999997 (0.000007) with: {'max_depth': 7, 'n_estimators': 300}\n",
      "0.999993 (0.000011) with: {'max_depth': 8, 'n_estimators': 100}\n",
      "0.999991 (0.000017) with: {'max_depth': 8, 'n_estimators': 150}\n",
      "0.999990 (0.000020) with: {'max_depth': 8, 'n_estimators': 200}\n",
      "0.999990 (0.000020) with: {'max_depth': 8, 'n_estimators': 250}\n",
      "0.999990 (0.000020) with: {'max_depth': 8, 'n_estimators': 300}\n",
      "Execution time:  18.97380232810974\n"
     ]
    }
   ],
   "source": [
    "stratified_k_fold_LGBM(X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malik_cyrus/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/malik_cyrus/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_error: 0.361569\ttraining's binary_logloss: 0.571374\tvalid_1's binary_error: 0.336221\tvalid_1's binary_logloss: 0.559228\n",
      "[2]\ttraining's binary_error: 0.361569\ttraining's binary_logloss: 0.503909\tvalid_1's binary_error: 0.336221\tvalid_1's binary_logloss: 0.493397\n",
      "[3]\ttraining's binary_error: 0.0176375\ttraining's binary_logloss: 0.44766\tvalid_1's binary_error: 0.0157011\tvalid_1's binary_logloss: 0.438336\n",
      "[4]\ttraining's binary_error: 0.0109074\ttraining's binary_logloss: 0.399589\tvalid_1's binary_error: 0.00974553\tvalid_1's binary_logloss: 0.391272\n",
      "[5]\ttraining's binary_error: 0.0104433\ttraining's binary_logloss: 0.358688\tvalid_1's binary_error: 0.00974553\tvalid_1's binary_logloss: 0.351038\n",
      "[6]\ttraining's binary_error: 0.00881875\ttraining's binary_logloss: 0.32205\tvalid_1's binary_error: 0.00757986\tvalid_1's binary_logloss: 0.314883\n",
      "[7]\ttraining's binary_error: 0.00858668\ttraining's binary_logloss: 0.290462\tvalid_1's binary_error: 0.00812128\tvalid_1's binary_logloss: 0.283506\n",
      "[8]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.262376\tvalid_1's binary_error: 0.00324851\tvalid_1's binary_logloss: 0.255628\n",
      "[9]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.237602\tvalid_1's binary_error: 0.00324851\tvalid_1's binary_logloss: 0.231017\n",
      "[10]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.215939\tvalid_1's binary_error: 0.00270709\tvalid_1's binary_logloss: 0.209418\n",
      "[11]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.196402\tvalid_1's binary_error: 0.00270709\tvalid_1's binary_logloss: 0.189968\n",
      "[12]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.178989\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.172607\n",
      "[13]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.163645\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.157245\n",
      "[14]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.149678\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.143295\n",
      "[15]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.137152\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.130766\n",
      "[16]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.125635\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.119385\n",
      "[17]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.115274\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.109143\n",
      "[18]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.106269\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.100065\n",
      "[19]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.0978016\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.0916969\n",
      "[20]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.0901603\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.0841433\n",
      "[21]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.0832579\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.077287\n",
      "[22]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.0770036\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.0711087\n",
      "[23]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.0713312\tvalid_1's binary_error: 0.00216567\tvalid_1's binary_logloss: 0.065434\n",
      "[24]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.0661927\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0603248\n",
      "[25]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.0612513\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0555473\n",
      "[26]\ttraining's binary_error: 0.00510559\ttraining's binary_logloss: 0.0567648\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0513118\n",
      "[27]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.0526701\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0473586\n",
      "[28]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.0488106\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0436106\n",
      "[29]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.0454108\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0403261\n",
      "[30]\ttraining's binary_error: 0.00440938\ttraining's binary_logloss: 0.0417386\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0368832\n",
      "[31]\ttraining's binary_error: 0.00371316\ttraining's binary_logloss: 0.0383901\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0337635\n",
      "[32]\ttraining's binary_error: 0.00371316\ttraining's binary_logloss: 0.0353388\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0309388\n",
      "[33]\ttraining's binary_error: 0.00371316\ttraining's binary_logloss: 0.0325602\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0283826\n",
      "[34]\ttraining's binary_error: 0.00371316\ttraining's binary_logloss: 0.0300699\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0260705\n",
      "[35]\ttraining's binary_error: 0.00371316\ttraining's binary_logloss: 0.0277646\tvalid_1's binary_error: 0.00162426\tvalid_1's binary_logloss: 0.0239688\n",
      "[36]\ttraining's binary_error: 0.0025528\ttraining's binary_logloss: 0.0256742\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0220438\n",
      "[37]\ttraining's binary_error: 0.0025528\ttraining's binary_logloss: 0.0237664\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0202951\n",
      "[38]\ttraining's binary_error: 0.0025528\ttraining's binary_logloss: 0.0220498\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0187196\n",
      "[39]\ttraining's binary_error: 0.0025528\ttraining's binary_logloss: 0.0204849\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0172772\n",
      "[40]\ttraining's binary_error: 0.00232072\ttraining's binary_logloss: 0.0190769\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0159737\n",
      "[41]\ttraining's binary_error: 0.00232072\ttraining's binary_logloss: 0.0177827\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0148389\n",
      "[42]\ttraining's binary_error: 0.00185658\ttraining's binary_logloss: 0.0165622\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0137199\n",
      "[43]\ttraining's binary_error: 0.00185658\ttraining's binary_logloss: 0.0154214\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0126738\n",
      "[44]\ttraining's binary_error: 0.00185658\ttraining's binary_logloss: 0.0144444\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0118222\n",
      "[45]\ttraining's binary_error: 0.00185658\ttraining's binary_logloss: 0.0134927\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0109724\n",
      "[46]\ttraining's binary_error: 0.00162451\ttraining's binary_logloss: 0.0126369\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.0101873\n",
      "[47]\ttraining's binary_error: 0.00162451\ttraining's binary_logloss: 0.0118472\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.00951013\n",
      "[48]\ttraining's binary_error: 0.00162451\ttraining's binary_logloss: 0.0111063\tvalid_1's binary_error: 0.00108284\tvalid_1's binary_logloss: 0.00886565\n",
      "[49]\ttraining's binary_error: 0.00092829\ttraining's binary_logloss: 0.010223\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.00814119\n",
      "[50]\ttraining's binary_error: 0.00092829\ttraining's binary_logloss: 0.00949719\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.00756112\n",
      "[51]\ttraining's binary_error: 0.00092829\ttraining's binary_logloss: 0.00876695\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00695653\n",
      "[52]\ttraining's binary_error: 0.00092829\ttraining's binary_logloss: 0.00810431\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00640872\n",
      "[53]\ttraining's binary_error: 0.00092829\ttraining's binary_logloss: 0.00757693\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00594807\n",
      "[54]\ttraining's binary_error: 0.00092829\ttraining's binary_logloss: 0.00708796\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00554359\n",
      "[55]\ttraining's binary_error: 0.00092829\ttraining's binary_logloss: 0.00657237\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00510052\n",
      "[56]\ttraining's binary_error: 0.000696217\ttraining's binary_logloss: 0.00608689\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00472189\n",
      "[57]\ttraining's binary_error: 0.000696217\ttraining's binary_logloss: 0.00563216\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00435128\n",
      "[58]\ttraining's binary_error: 0.000696217\ttraining's binary_logloss: 0.00522923\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00404166\n",
      "[59]\ttraining's binary_error: 0.000696217\ttraining's binary_logloss: 0.00487046\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00373444\n",
      "[60]\ttraining's binary_error: 0.000696217\ttraining's binary_logloss: 0.00452656\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00344698\n",
      "[61]\ttraining's binary_error: 0.000696217\ttraining's binary_logloss: 0.00420975\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00321559\n",
      "[62]\ttraining's binary_error: 0.000696217\ttraining's binary_logloss: 0.00396753\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.0030027\n",
      "[63]\ttraining's binary_error: 0.000464145\ttraining's binary_logloss: 0.00369915\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.0027845\n",
      "[64]\ttraining's binary_error: 0.000464145\ttraining's binary_logloss: 0.00349694\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00260474\n",
      "[65]\ttraining's binary_error: 0.000464145\ttraining's binary_logloss: 0.00330773\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.0024245\n",
      "[66]\ttraining's binary_error: 0.000464145\ttraining's binary_logloss: 0.00313831\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00226962\n",
      "[67]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.00293237\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00210774\n",
      "[68]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.00278797\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00197131\n",
      "[69]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.0026116\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00182442\n",
      "[70]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.00245106\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00170359\n",
      "[71]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.00233716\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00159798\n",
      "[72]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.00222988\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00150188\n",
      "[73]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.0020853\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00139139\n",
      "[74]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.00195909\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00129001\n",
      "[75]\ttraining's binary_error: 0.000232072\ttraining's binary_logloss: 0.0018591\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00120214\n",
      "[76]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00176721\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00113467\n",
      "[77]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00166468\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00105968\n",
      "[78]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00157074\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000989453\n",
      "[79]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00148444\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000927315\n",
      "[80]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00141286\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000887662\n",
      "[81]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00135282\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000842848\n",
      "[82]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00128358\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000795898\n",
      "[83]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00123276\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00075739\n",
      "[84]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00115603\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000716679\n",
      "[85]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.0010865\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000682704\n",
      "[86]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00101567\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00064837\n",
      "[87]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000966632\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000628686\n",
      "[88]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000926401\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000615754\n",
      "[89]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000884519\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000602684\n",
      "[90]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000849381\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000575151\n",
      "[91]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000812971\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00056524\n",
      "[92]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000763033\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000547161\n",
      "[93]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000718296\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000531768\n",
      "[94]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000689257\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000529159\n",
      "[95]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000650047\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000524543\n",
      "[96]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000613946\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000514856\n",
      "[97]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000587263\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000517961\n",
      "[98]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000555748\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000511758\n",
      "[99]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000534459\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000520343\n",
      "[100]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000507753\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000513477\n",
      "[101]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000481689\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000510081\n",
      "[102]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000463654\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000523347\n",
      "[103]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000440644\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00052326\n",
      "[104]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000416415\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000513744\n",
      "[105]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000393825\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000487518\n",
      "[106]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000376324\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000471765\n",
      "[107]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000357306\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000456086\n",
      "[108]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000340362\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000456449\n",
      "[109]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000325407\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000427329\n",
      "[110]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000314156\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000442617\n",
      "[111]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.0003001\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000446544\n",
      "[112]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000288832\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000462537\n",
      "[113]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000276734\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000464988\n",
      "[114]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000266817\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000486015\n",
      "[115]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000254985\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000492414\n",
      "[116]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000241786\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.0004889\n",
      "[117]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000223413\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000460252\n",
      "[118]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000214056\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000443969\n",
      "[119]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000207395\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000439581\n",
      "[120]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.0002001\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.00046091\n",
      "[121]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000191439\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.00046805\n",
      "[122]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000185807\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000464015\n",
      "[123]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000179406\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000487508\n",
      "[124]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000167502\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000457699\n",
      "[125]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000161102\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000469451\n",
      "[126]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000150744\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000440719\n",
      "[127]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000141334\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000413471\n",
      "[128]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000138366\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000435787\n",
      "[129]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000133933\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000430528\n",
      "[130]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000129515\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000454826\n",
      "[131]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000124355\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000426925\n",
      "[132]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000119083\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000419708\n",
      "[133]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000115517\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00041523\n",
      "[134]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.00011313\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000438684\n",
      "[135]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000107839\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000438178\n",
      "[136]\ttraining's binary_error: 0\ttraining's binary_logloss: 0.000101136\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000411526\n",
      "[137]\ttraining's binary_error: 0\ttraining's binary_logloss: 9.50444e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000386224\n",
      "[138]\ttraining's binary_error: 0\ttraining's binary_logloss: 9.10217e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000384052\n",
      "[139]\ttraining's binary_error: 0\ttraining's binary_logloss: 8.76554e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.00035957\n",
      "[140]\ttraining's binary_error: 0\ttraining's binary_logloss: 8.41151e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000358009\n",
      "[141]\ttraining's binary_error: 0\ttraining's binary_logloss: 8.16244e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000353966\n",
      "[142]\ttraining's binary_error: 0\ttraining's binary_logloss: 7.93945e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000361351\n",
      "[143]\ttraining's binary_error: 0\ttraining's binary_logloss: 7.46709e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000338639\n",
      "[144]\ttraining's binary_error: 0\ttraining's binary_logloss: 7.30508e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000359426\n",
      "[145]\ttraining's binary_error: 0\ttraining's binary_logloss: 7.10011e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000355867\n",
      "[146]\ttraining's binary_error: 0\ttraining's binary_logloss: 6.94286e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000377246\n",
      "[147]\ttraining's binary_error: 0\ttraining's binary_logloss: 6.53145e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000353921\n",
      "[148]\ttraining's binary_error: 0\ttraining's binary_logloss: 6.32601e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000375702\n",
      "[149]\ttraining's binary_error: 0\ttraining's binary_logloss: 5.93138e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000390551\n",
      "[150]\ttraining's binary_error: 0\ttraining's binary_logloss: 5.767e-05\tvalid_1's binary_error: 0\tvalid_1's binary_logloss: 0.000386774\n",
      "[151]\ttraining's binary_error: 0\ttraining's binary_logloss: 5.44038e-05\tvalid_1's binary_error: 0.000541419\tvalid_1's binary_logloss: 0.000410234\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(learning_rate=0.09,\n",
    "                            max_depth=4,\n",
    "                            subsample=0.5, \n",
    "                            objective='binary',\n",
    "                            n_estimators=300)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "# clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=[\"error\", \"logloss\"],\n",
    "#           eval_set=eval_set, verbose=True)\n",
    "clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=[\"error\", \"logloss\"],\n",
    "              eval_set=eval_set, verbose=True)\n",
    "\n",
    "# predict\n",
    "y_pred = clf.predict(X_test)\n",
    "predicted_values = [round(val) for val in y_pred]\n",
    "\n",
    "# evaluation \n",
    "accuracy = accuracy_score(y_test, predicted_values)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# performance metrics \n",
    "results = clf.evals_result_\n",
    "epochs = len(results['training']['binary_error'])\n",
    "x_axis = range(0, epochs)\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "# plotting log loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['training']['binary_logloss'], label='Train')\n",
    "ax.plot(x_axis, results['valid_1']['binary_logloss'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('Log Loss')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.title('LightGBM Log Loss')\n",
    "plt.show()\n",
    "# plot classification error\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['training']['binary_error'], label='Train')\n",
    "ax.plot(x_axis, results['valid_1']['binary_error'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('Classification Error')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.title('LightGBM Classification Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['Illicit', 'likely-reputable'], \n",
    "                     columns = ['Illicit', 'likely-reputable'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='GnBu')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Model: 100.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1226\n",
      "           1       1.00      1.00      1.00       621\n",
      "\n",
      "    accuracy                           1.00      1847\n",
      "   macro avg       1.00      1.00      1.00      1847\n",
      "weighted avg       1.00      1.00      1.00      1847\n",
      "\n",
      "ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# classifier = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", random_state=0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# print(\"Accuracy for Random Forest Model: %.2f\" % (accuracy_score(y_test, y_pred) * 100))\n",
    "# report = classification_report(y_test, y_pred)\n",
    "# print(report)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_model = rfc.fit(X_train, y_train)\n",
    "pred8 = rfc_model.predict(X_test)\n",
    "print(\"Accuracy for Random Forest Model: %.2f\" % (accuracy_score(y_test, pred8) * 100))\n",
    "print(classification_report(y_test, pred8))\n",
    "roc = roc_auc_score(y_test, rfc_model.predict_proba(X_test)[:, 1])\n",
    "print(\"ROC:\" , roc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d01d3e927f2d10c917122a4d7c308c03189da167853c27df2d9c3623e11eb447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
